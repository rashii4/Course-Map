\# Reflection





Working with AI on this project was honestly a mix of helpful and slightly overwhelming at times. I enjoyed the process overall because it made complex parts of the assignment feel more manageable, especially when dealing with NetworkX and graph metrics. There were moments where I felt stuck trying to understand why something wasn’t working, and using AI helped me move past those blocks faster.



That said, I did get confused at certain points. Sometimes the explanations were very technical, and I had to slow down and really make sure I understood what the code was doing instead of just copying it. I found that the most important part was testing everything myself and making sure I could explain it in my own words. If I couldn’t explain it, I knew I needed to go back and review it.



I think the most interesting part of this project was seeing how scraping raw web content could turn into something analytical. At the beginning, it just felt like extracting text from a website. But once I built the graph and started computing centrality measures, it became much more meaningful. The AI helped me refine and structure that analysis, but I still had to understand what in-degree, out-degree, and betweenness centrality actually represented in the context of the curriculum.



Overall, I did enjoy working with AI as a support tool. It made the process more efficient, but it also required me to stay actively engaged. I realized that AI works best when I treat it as a collaborator rather than a shortcut. I still needed to think critically, adjust the code, and interpret the results myself.



This project helped me become more comfortable combining web scraping, structured data, and network analysis. It also made me more aware of how important it is to understand the tools I’m using, rather than just relying on them.

